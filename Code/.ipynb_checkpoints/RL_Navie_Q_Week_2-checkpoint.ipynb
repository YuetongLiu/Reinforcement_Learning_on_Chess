{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warpper\n",
    "\n",
    "Most gym environment have space in multi-dimension (Box format). To save memory, we apply a wrapper to discretize the observation. \n",
    "\n",
    "env.unwrapped will give back the internal original environment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscretizedObservationWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"This wrapper converts a Box observation into a single integer.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, n_bins=10, low=None, high=None):\n",
    "        super().__init__(env)\n",
    "        assert isinstance(env.observation_space, gym.spaces.Box)\n",
    "\n",
    "        low = self.observation_space.low if low is None else low\n",
    "        high = self.observation_space.high if high is None else high\n",
    "\n",
    "        self.n_bins = n_bins\n",
    "        self.val_bins = [np.linspace(l, h, n_bins + 1) for l, h in\n",
    "                         zip(low, high)]\n",
    "        self.observation_space = gym.spaces.Discrete(n_bins ** len(low))\n",
    "\n",
    "    def _convert_to_one_number(self, digits):\n",
    "        return sum([d * ((self.n_bins + 1) ** i) for i, d in enumerate(digits)])\n",
    "\n",
    "    def observation(self, observation):\n",
    "        digits = [np.digitize([x], bins)[0]\n",
    "                  for x, bins in zip(observation, self.val_bins)]\n",
    "        return self._convert_to_one_number(digits)\n",
    "\n",
    "\n",
    "env = DiscretizedObservationWrapper(\n",
    "    env, \n",
    "    n_bins=8, \n",
    "    low=[-2.4, -2.0, -0.42, -3.5], \n",
    "    high=[2.4, 2.0, 0.42, 3.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Q-Learning\n",
    "\n",
    "The key point of Naive Q-learning is while estimating what is the next action, it does not follow the current policy but rather adopt the best Q value independently. Here is the Bellman equation we will use.\n",
    "\n",
    "$Q(s,a)←(1−α)Q(s,a)+α(r+γ*maxQ(s′,a′))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Update Q value\n",
    "\n",
    "The Q value for all (s, a) pairs can be simply tracked in a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "Q = defaultdict(float)\n",
    "\n",
    "gamma = 0.99  # Discounting factor\n",
    "alpha = 0.5  # soft update param\n",
    "actions = range(env.action_space.n) # all possible actions\n",
    "\n",
    "# Calculate Q Value    \n",
    "def update_Q(s, r, a, s_next, done):\n",
    "    # s: observations\n",
    "    # r: reward \n",
    "    # a: actions\n",
    "    # s_next: same as s\n",
    "    # done: bool\n",
    "    \n",
    "    max_q_next = max([Q[s_next, a] for a in actions])  # get max Q value of (s', a')\n",
    "    \n",
    "    # Do not include the next state's value if currently at the terminal state.\n",
    "    Q[s, a] += alpha * (r + gamma * max_q_next * (1.0 - done) - Q[s, a]) # the Bellman equation to update Q value. \n",
    "    # If done is True, Q(s,a) = (1-alpha)*Q(s,a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Action \n",
    "\n",
    "Action is decided based on max Q value and we use ε-greedy to force exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1  # 10% chances to apply a random action\n",
    "\n",
    "def act(ob): \n",
    "    if np.random.random() < epsilon:\n",
    "        # action_space.sample() is a convenient function to get a random action\n",
    "        # that is compatible with this given action space.\n",
    "        return env.action_space.sample()\n",
    "\n",
    "    # Pick the action with highest q value.\n",
    "    qvals = {a: Q[ob, a] for a in actions}\n",
    "    max_q = max(qvals.values())  # get best Q value \n",
    "    # In case multiple actions have the same maximum q value.\n",
    "    actions_with_max_q = [a for a, q in qvals.items() if q == max_q] # range(2); max_q\n",
    "    return np.random.choice(actions_with_max_q)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Compare the total reward using Naive Q-learning and random play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10000\n",
    "\n",
    "ob = env.reset()\n",
    "rewards = [] # reward for each round \n",
    "reward = 0.0 # total reward in one round\n",
    "\n",
    "for step in range(n_steps):\n",
    "    #env.render()\n",
    "    a = act(ob)\n",
    "    ob_next, r, done, _ = env.step(a)\n",
    "    update_Q(ob, r, a, ob_next, done)\n",
    "    reward += r\n",
    "    if done:\n",
    "        rewards.append(reward)\n",
    "        reward = 0.0\n",
    "        ob = env.reset()\n",
    "    else:\n",
    "        ob = ob_next\n",
    "env.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10000\n",
    "\n",
    "ob = env.reset()\n",
    "rewards_r = [] # reward for each round \n",
    "reward = 0.0 # total reward in one round\n",
    "for step in range(n_steps):\n",
    "    #env.render()\n",
    "    \n",
    "    ob_next, r, done, _ = env.step(env.action_space.sample())\n",
    "    reward += r\n",
    "    if done:\n",
    "        rewards_r.append(reward)\n",
    "        reward = 0.0\n",
    "        ob = env.reset()\n",
    "    else:\n",
    "        ob = ob_next\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'reward for naive_q')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=rewards).set_title('reward for naive_q')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'reward for random')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=rewards_r).set_title('reward for random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot, there is a significant increase on reward after applying Naive Q_learning method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
